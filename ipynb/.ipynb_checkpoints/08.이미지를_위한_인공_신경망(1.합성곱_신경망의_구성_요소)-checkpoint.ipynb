{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d669841e-eaac-42b8-9f7b-49205b5ce4f3",
   "metadata": {},
   "source": [
    "# 08-1 합성곱 신경망의 구성 요소\n",
    "##### 합성곱 신경망을 구성하는 기본 개념과 동작 원리를 배우고 간단한 합성곱, 풀링 계산 방법을 배움\n",
    "\n",
    "- 앞서 로지스틱 회귀 성능은 81% 정도였는데 딥러닝 성능은 87% 정도로 향상됨\n",
    "- 성능 향상을 위한 합성곱 기법을 배움\n",
    "\n",
    "### 합성곱\n",
    "- 합성곱(convolution) : 입력 데이터에 유용한 특성만 저장\n",
    "- 7장에서 사용한 밀집층은 뉴런마다 입력 개수만큼의 가중치가 있음. 그림으로 확인해보자\n",
    "![가중치](./images/convolution-423-1.jpg)\n",
    "\n",
    "- 인공 신경망은 가중치 w<sub>1</sub>~w<sub>10</sub>과 절편 b를 랜덤하게 초기화 한 후 다음 에포크를 반복하며 경사 하강법 알고리즘을 사용하여 손실이 낮아지도록 최적의 가중치와 절편을 찾아감\n",
    "- 합성곱은 밀집층의 계산과 조금 다름\n",
    "  - 입력 데이터 전체가 아닌 일부에 가중치를 곱함\n",
    "  - 이 뉴런이 3개의 가중치를 가진다고 가정하고 아래의 이미지 확인\n",
    "![합성곱설명-1](./images/convolution-424-1.jpg)\n",
    "- 가중치 w<sub>1</sub>~w<sub>3</sub>이 입력의 처음 3개 특성과 곱해져 1개 출력을 만듦\n",
    "- 이 뉴런이 한 칸 아래로 이동해 두 번째부터 네 번째 특성과 곱해져 새로운 출력을 만듦\n",
    "![합성곱설명-2](./images/convolution-424-2.jpg)\n",
    "- 여기에서 중요한 것은 첫 번쨰 합성곱에 사용된 가중치 w<sub>1</sub>~w<sub>3</sub>과 절편 b가 두 번째 합성곱에도 동일하게 사용\n",
    "- 한 칸씩 이동하면서 출력을 만드는 것이 합성곱\n",
    "- 여기서는 뉴런 가중치가 3개이기 때문에 총 8개의 출력이 만들어짐\n",
    "\n",
    "![합성곱설명-3](./images/convolution-425-1.jpg)\n",
    "\n",
    "- 색은 다르지만 모두 같은 가중치 w<sub>1</sub>~w<sub>3</sub>와 절편 b를 사용\n",
    "- 합성곱 층의 뉴런에 있는 가중치 개수는 정하기 나름 -> 하이퍼파라미터\n",
    "- 신경망 층의 그림은 뉴런이 길게 늘어서 있고 서로 조밀하게 연결 -> 합성곱에서는 뉴런이 입력 위를 이동하며 출력을 만듦\n",
    "- 합성곱 신경망(CNN, convolutional neural network)에서는 완전 연결 신경망과 달리 뉴런을 필터(filter) 혹은 커널(kernel)이라고 부름\n",
    "\n",
    "- 케라스에서는 아래와 같이 명명함\n",
    "  - 필터 : 뉴런 개수\n",
    "  - 커널 : 입력에 곱해지는 가중치\n",
    "- 합성곱의 장점은 1차원이 아니라 2차원 입력에도 적용할 수 있다는 것\n",
    "![합성곱설명-4](./images/convolution-426-1.jpg)\n",
    "- 입력이 2차원 배열이면 필터도 2차원\n",
    "- 위 그림에서 필터의 커널 크기는 (3,3)으로 가정 => 하이퍼파라미터이기 때문\n",
    "- 왼쪽 위 모서리부터 합성곱 시작, 입력의 9개 원소와 커널의 9개 가중치를 곱한 후 절편을 더해 1개의 출력을 만듦\n",
    "![합성곱설명-5](./images/convolution-426-2.jpg)\n",
    "- 필터가 한칸씩 이동하며 합성곱을 수행\n",
    "- 합성곱은 마치 도장을 찍듯이 왼쪽에서 오른쪽 맨 아래까지 이동하면서 출력을 만듦\n",
    "- 계산식은 밀집층과 비슷 그림에서의 필터는 4번 이동하므로 4개의 출력을 만듦\n",
    "![합성곱설명-6](./images/convolution-427-1.jpg)\n",
    "- 4개의 출력을 필터가 입력에 놓인 위치에 맞게 2차원으로 배치\n",
    "- 왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래 모두 4개의 위치에 해당 값을 놓음 -> (4,4) 크기의 입력을 (2,2)로 압축\n",
    "- 특성 맵(feature map) : 합성곱 계산을 통해 얻은 출력\n",
    "- 밀집층에서 여러 개의 뉴런을 사용하듯이 합성곱 층에서 여러 개의 필터를 사용\n",
    "- (2,2) 크기의 특성 맵을 쌓으면 3차원 배열이 됨\n",
    "- 아래 그림에서 (2, 2, 3)의 3차원 배열을 소개함\n",
    "![합성곱설명-7](./images/convolution-428-1.jpg)\n",
    "- 밀집층에 있는 뉴런 가중치가 모두 다르듯이 합성곱 층에 있는 필터 가중치(커널)도 모두 다름 -> 같은 가중치를 가진 필터를 여러 개 사용할 필요 없음\n",
    "- 2차원 구조를 그대로 사용하기 떄문에 이미지 처리 분야에서 합성곱이 뛰어난 성능을 발휘함\n",
    "\n",
    "### 케라스 합성곱 층\n",
    "- 합성곱 층도 keras.laysers 패키지 아래 있음\n",
    "- 입력 위를 이동하는 합성곱은 Conv2D 클래스로 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711dcbdc-321b-4a7b-895f-e26e59d3a843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 12:45:19.674454: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.convolutional.conv2d.Conv2D at 0x1367ee510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c933b572-f0e5-42dc-965e-701ea27c3c7f",
   "metadata": {},
   "source": [
    "- 여기서 잠깐\n",
    "  - 특성 맵은 활성화 함수를 적용 한 후를 이야기함, 일반적으로 특성 맵은 활성화 함수를 통과한 값임\n",
    "  - 커널의 크기는 하이퍼파라미터이므로 여러 값을 시도해봐야하지만 일반적으로 (3,3), (5,5) 사용\n",
    "- Conv2D 클래스의 첫 번째 매개변수는 필터의 개수임\n",
    "- kernel_size 매개변수는 필터에 사용할 커널의 크기를 지정\n",
    "  - 필터 개수와 커널 크기는 반드시 지정해야 하는 매개변수\n",
    "- 활성화 함수를 지정 (여기서는 렐루 함수 서낵)\n",
    "- 합성곱 신경망의 정의\n",
    "  - 1개 이상의 합성곱 층을 사용한 인공 신경망\n",
    "\n",
    "#### 패딩과 스트라이드\n",
    "- 앞의 예제는 (4,4) 크기 입력에 (3,3) 크기 커널을 적용하여 (2,2) 크기 특성맵을 만듦\n",
    "- 앞의 예제와 달리 커널 크기는 (3,3)으로 두고 출력의 크기를 입력과 동일할게 (4,4)로 만들려면 어떻게 해야할까?\n",
    "- 더 큰 입력에 합성곱을 곱하는 척해야 함\n",
    "\n",
    "![합성곱설명-7](./images/convolution-430-1.jpg)\n",
    "\n",
    "- 실제 입력 크기는 (4,4)\n",
    "- (6,6)처럼 다뤄서 (3,3) 커널로 출력\n",
    "\n",
    "![합성곱설명-8](./images/convolution-430-2.jpg)\n",
    "\n",
    "- 이렇게 입력 배열 주위를 가상의 원소로 채우는 것을 **패딩(padding)** 이라고 함\n",
    "- 실제 입력값이 아니기 때문에 패딩은 보통 0으로 채워줌(계산에 영향을 미치지 않게 하기 위해)\n",
    "\n",
    "![합성곱설명-9](./images/convolution-431-1.jpg)\n",
    "\n",
    "- **세임 패딩(same padding)** : 입력과 특성 맵의 크기를 동일하게 만들기 위해 주위에 0으로 패딩하는 것\n",
    "- **밸리드 패딩(valid padding)** : 패딩 없이 순수한 입력 배열로 합성곱하여 특성 맵을 만드는 경우\n",
    "  - 특성 맵의 크기가 줄어들 수밖에 없음\n",
    "- 패딩을 하지 않으면 커널이 지나가며 모서리는 딱 한번만 찍힘\n",
    "- 반면 다른 원소들은 2번 이상 커널과 계산됨\n",
    "\n",
    "![합성곱설명-10](./images/convolution-431-2.jpg)\n",
    "\n",
    "- 1픽셀을 패딩하면 이 비율은 크게 줄어들고 2 픽셀을 패딩하면 중앙부와 모서리 픽셀이 합성곱에 참여하는 비율이 동일해짐 ((4:1), (9:4), (1:1))\n",
    "\n",
    "![합성곱설명-11](./images/convolution-432-1.jpg)\n",
    "\n",
    "- 적절한 패딩은 이미지의 주변에 있는 정보를 잃어버리지 않도록 도와줌\n",
    "- 일반적으로 합성곱 신경망에서는 세임 패딩이 많이 사용됨\n",
    "- 케라스 Conv2D 클래스는 padding 매개변수로 사용 가능. 기본값은 valid, 세임 패딩은 same\n",
    "\n",
    "```python\n",
    "keras.layers.Conv2D(10, kenel_size=(3,3), activation='relu', padding='same')\n",
    "```\n",
    "\n",
    "- 지금까지 본 합성곱 연산은 좌우, 위아래로 한칸씩 이동함\n",
    "- 두 칸씩 건너뛸 수도 있음(특성 맵 크기가 더 작아짐)\n",
    "- 이러한 이동의 크기를 스트라이드(stride)라고 함. 기본으로 스트라이드는 1 (strides 매개변수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3455b77b-7ec4-491b-9bf4-21de88ecefe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.convolutional.conv2d.Conv2D at 0x134368b50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu', padding='same', strides=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4afdf-c77a-49d6-8965-92d4742f591e",
   "metadata": {},
   "source": [
    "- strides 매개변수는 오른쪽, 아래쪽으로 이동하는 크기를 (1,1)와 같이 각각 지정할 수 있음\n",
    "  - 하지만 커널 이동 크기를 가로세로 방향으로 다르게 지정하는 경우는 거의 없음\n",
    "- 이제 풀링을 알아보자\n",
    "\n",
    "#### 풀링\n",
    "- 풀링(pooling) : 합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄이는 역할을 수행\n",
    "  - 특성 맵의 개수는 줄이지 않음\n",
    "\n",
    "![합성곱설명-12](./images/convolution-435-1.jpg)\n",
    "\n",
    "- 풀링도 합성곱처럼 입력 위를 지나가며 도장을 찍음\n",
    "- 풀링은 가중치가 없고 영역에서 가장 큰 값을 고르거나 평균값을 계산함. 이를 최대 풀링(max pooling), 평균 풀링(이라 함\n",
    "- 아래와 같은 (4,4) 크기의 특성 맵이 있다고 가정\n",
    "  - 여기에 (2,2) 최대 풀링을 적용하면 절반 크기로 줄어듦\n",
    "\n",
    "![합성곱설명-13](./images/convolution-435-2.jpg)\n",
    "\n",
    "- 최대 풀링은 가장 큰 값을 고르기 때문에 (2,2) 영역에서 9, 7, 8, 6을 차례로 골라 (2,2) 크기 출력이 나옴\n",
    "- 특성 맵이 여러개라면 동일 작업을 반복함.\n",
    "- 여기서 잠깐 : 풀링 층의 출력도 특성 맵이라고 함. 합성곱 신경망에서는 합성곱 층과 풀링 층에서 출력되는 값 모두를 특성맵이라고 함\n",
    "- 케라스에서는 MaxPooling2D(2) 클래스로 풀링을 수행함\n",
    "\n",
    "```python\n",
    "keras.layers.MaxPooling2D(2)\n",
    "```\n",
    "\n",
    "- MaxPooling2D의 첫 번째 매개변수로 풀링의 크기 지정 (대부분은 2)\n",
    "  - 가로세로 크기를 2로 줄임\n",
    "  - 가로세로 풀링 크기를 다르게 하려면 (2, 3) 이렇게 지정할 수 있음 (극히 드문 경우)\n",
    "- 합성곱 층과 마찬가지로 strides, padding 매개변수 제공\n",
    "  - strides의 기본값은 풀링의 크기이므로 따로 지정 필요 없음\n",
    "  - padding 기본값은 valid로 패징 하지 않음\n",
    "  - 풀링은 패딩을 하지 않기 때문에 이 매개변수를 바꾸는 경우는 거의 없음\n",
    "- 평균 풀링을 제공하는 클래스는 AveragePooling2D\n",
    "  - 많은 경우 최대 풀링을 많이 사용함 (평균으로 특성 맵에 있는 중요 정보를 (평균하여) 희석시킬 수 있기 때문\n",
    "- 풀링은 가로세로 방향으로만 진행\n",
    "- 특성 맵 개수는 변하지 않고 그대로임\n",
    "- 이제 합성곱 전체 구조를 살펴보자\n",
    "\n",
    "### 합성곱 신경망의 전체 구조\n",
    "- 합성곱의 층, 필터, 패딩, 스트라이드, 풀링 등 중요 개념을 살펴봄\n",
    "- 합성곱 신경망은 일반적으로 너비와 높이가 있는 이미지이기 때문에 입체적으로 설명\n",
    "\n",
    "![합성곱설명-14](./images/convolution-437-1.jpg)\n",
    "\n",
    "- 합성곱 층(1번)에서 사용할 커널의 크기는 (3,3) 크기이고 세임 패딩이므로 1픽셀이 입력 데이터 주변에 추가됨\n",
    "- 패딩은 텐서플로에서 자동으로 추가하므로 수동으로 입력에 어떤 작업을 추가할 필요가 없음\n",
    "\n",
    "- 위 그림에서 합성곱 필터는 3개.\n",
    "- 각 (3,3) 크기의 가중치를 가지고 있으며 필터마다 절편이 하나씩 있음 (도장마다 절편 b가 끝에 있음)\n",
    "- 밀집층의 뉴런과 마찬가지로 필터의 가중치는 각기 서로 다름\n",
    "\n",
    "- 합성곱 스트라이드는 1\n",
    "- 특성 맵의 크기는 입려과 동일한 (4,4)\n",
    "- 3개의 필터가 하나씩 합성곱의 출력을 만들고 이 출력이 합쳐져서 (4,4,3) 크기의 특성 맵이 만들어짐\n",
    "- 밀집층과 마찬가지로 합성곱 층에서도 활성화 함수를 적용함\n",
    "- 합성곱 층은 활성화 함수로 렐루 함수를 많이 사용함\n",
    "- 그 다음은 풀링 층(2번). 풀링 층은 합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄임\n",
    "- 보통 (2,2) 풀링을 사용해 절반으로 줄임. 특성 맵 개수는 변하지 않으므로 (4,4,3)에서 (2,2,3)으로 특성 맵 개수 유지된 것 확인 가능\n",
    "- 풀링 사용 이유 : 합성곱에서 스트라이드를 크게 하여 특성 맵을 줄이는 것보다 풀링 층에서 크기를 줄이는 것이 경험적으로 나은 성능이 남\n",
    "- 합성곱 신경망은 이렇게 합성곱 층에서 특성 맵을 생성하고 풀링에서 크기를 줄이는 구조가 쌍을 이룸\n",
    "- 풀링을 거친 특성 맵의 크기는 절반으로 줄었기 때문에 (2,2,3)이 됨\n",
    "- 밀집층(3번)인 출력층에 전달하려면 3차원 배열을 1차원으로 펼쳐야 함\n",
    "- 이 배열은 12개 원소를 가진 1차원 배열이고 출력층의 입력이 됨\n",
    "\n",
    "- 출력층에는 3개의 뉴런을 둠 - 3개의 클래스를 분류하는 다중 분류 문제임. 출력층에서 계산된 값은 소프트맥스 활성화 함수를 거쳐 최종 예측 확률이 됨\n",
    "\n",
    "#### 컬러 이미지를 사용한 합성곱\n",
    "- 지금까지 우리는 입력을 2차원 배열이라고 가정했음\n",
    "- MNIST 데이터는 실제 흑백 이미지이기 떄문이었지만 컬러라면 어떨까\n",
    "- 컬러 이미지는 RGB(빨강, 초록, 파랑) 채널로 구성되어 있기 때문에 3차원 배열로 표시\n",
    "\n",
    "![합성곱설명-15](./images/convolution-438-1.jpg)\n",
    "\n",
    "- 하나의 컬러 이미지는 너비, 높이, 차원(또는 채널 차원)이 있음\n",
    "- 앞의 예제에서 입력이 (4,4)가 아니라 (4,4,3)이 됨.\n",
    "- 필터의 커널 크기가 (3,3,3)이 됨\n",
    "- 커널 배열의 깊이는 항상 입력의 깊이와 같음\n",
    "\n",
    "![합성곱설명-16](./images/convolution-439-1.jpg)\n",
    "\n",
    "- 위 합성곱의 계산은 (3,3,3) 영역에 해당하는 27개 원소에 27개 가중치를 곱하고 절편을 더하는 식\n",
    "\n",
    "![합성곱설명-17](./images/convolution-439-2.jpg)\n",
    "\n",
    "- 중요한 것은 입력, 필터의 차원이 몇 개인지 상관없이 항상 출력은 하나의 값이라는 점 (특성 맵에 한 원소가 채워짐)\n",
    "- 케라스 합성곱 층은 항상 3차원의 입력을 기대함 (흑백일 경우 깊이 차원이 1인 3차원의 배열로 전달, (28, 28, 1))\n",
    "\n",
    "![합성곱설명-18](./images/convolution-440-1.jpg)\n",
    "\n",
    "- 위와 비슷한 경우가 또 있음 -> 합성곱 층-풀링 층 다음에 다시 합성곱 층이 올때\n",
    "  - 첫 번째 합성곱 층의 필터 개수가 5개라고 가정하여 첫 번째 풀링 층을 통과한 특성 맵 크기가 (4,4,5)라 가정\n",
    "  - 두 번째 합성곱 층에서 필터 너비와 높이가 각각 3이라면 이 필터의 커널 크기는 (3,3,5)가 됨\n",
    "  - 입력의 깊이와 필터의 깊이는 같아야 하기 때문\n",
    "  - 아래 그림처럼 (3 X 3 X 5 = 45)개의 가중치를 곱하고 절편을 더한 이 합성곱의 결과는 1개의 출력을 만듦\n",
    "\n",
    "![합성곱설명-19](./images/convolution-440-2.jpg)\n",
    "\n",
    "- 두 번째 합성곱 층의 필터 개수가 10개라면 만들어진 특성 맵의 크기는 (2,2,10)이 될 것\n",
    "- 합성곱 신경망은 너비와 높이는 점점 줄어들고 깊이는 점점 깊어지는 것이 특징\n",
    "- 마지막에 출력층 전에 특성 맵을 모두 펼쳐 밀집층의 입력으로 사용\n",
    "- 합성곱 신경망에서 필터는 이미지에 있는 어떤 특징을 찾는다고 생각할 수 있음\n",
    "- 처음에는 간단한 기본적인 특징 (직선, 곡선)을 찾고 층이 깊어질수록 다양하고 구체적인 특징을 감지할 수 있도록 필터의 개수를 늘림\n",
    "- 또 어떤 특징이 이미지의 어느 위치에 놓이더라도 쉽게 감지할 수 있도록 너비와 높이의 차원을 점점 줄여감\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
