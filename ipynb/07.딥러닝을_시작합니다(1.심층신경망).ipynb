{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced2c8b1-6bdc-41b6-82da-ccec3eb8fbf0",
   "metadata": {},
   "source": [
    "# 07-2 심층 신경망\n",
    "##### 인공 신경망에 층을 여러 개 추가하여 패션 MNIST 데이터셋을 분류하면서 케라스로 심층 신경망을 만드는 방법을 알아보자\n",
    "\n",
    "- 1절에서 만들었던 인공 신경망의 성능을 더 높여보자\n",
    "\n",
    "### 2개의 층\n",
    "- 케라스 API에서 MNIST 데이터셋을 불러오자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2407e641-a071-4ab6-b28a-447907970ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-25 17:54:45.270292: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cbf110-46fa-4d28-9c49-9e5175aa93b6",
   "metadata": {},
   "source": [
    "- 픽셀값을 0 ~ 255 범위에서 0 ~ 1 사이로 변환\n",
    "- 28 X 28크기의 2차원 배열을 784 크기의 1차원 배열로 변경\n",
    "- train_test_split() 함수로 훈련 세트와 검증 세트를 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed8e839-e4df-47e7-b12e-e5449b2d9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_scaled = train_input / 255.0\n",
    "train_scaled = train_scaled.reshape(-1, 28*28)\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2a257-0d18-49bf-82e1-0d072149ca71",
   "metadata": {},
   "source": [
    "- 이제 인공 신경망 모델에 층을 2개 추가\n",
    "- 만들어진 모델의 대략적인 구조는 아래와 같음\n",
    "![심층신경망](./dnn-367-1.jpg)\n",
    "- 인공 신경망에서 입력층과 출력층 사이에 은닉층(hidden layer)이 추가됨\n",
    "- 활성화 함수 : 신경망 층의 선형 방정식의 계산 값에 적용하는 함수 (소프트맥스 함수 역시 활성화 함수)\n",
    "  - 출력층에 적용하는 활성화 함수는 종류가 제한되어 있음 (이진분류 : 시그모이드, 다중 분류 : 소프트맥스)\n",
    "  - 은닉층의 활성화 함순는 사용이 자유로움. 시그모이드 함수와 렐루(ReLU) 함수 등을 사용\n",
    "- 은닉층에 활성화 함수를 적용하는 이유\n",
    "  - 선형 방정식에서 b를 치환시켜 b의 역할을 제거 :\n",
    "    - $a \\times 4 + 2 = b$\n",
    "    - $b \\times 3 - 5 = c $\n",
    "    - $a \\times 12 + 1 = c$\n",
    "  - 신경망에서도 마찬가지임. 은닉층에서 선형적인 산술 계산만 수행한다면 수행 역할이 없는 셈\n",
    "  - 선형 계산을 적당히 비선형으로 비틀어주어야 함\n",
    "    - 다음 층의 계산과 단순히 합쳐지지 않고 나름의 역할을 수행하기 위함 (아래의 식과 같음)\n",
    "    - $a \\times 4 + 2 = b$\n",
    "    - $log(b) = k$\n",
    "    - $k \\times 3 - 5 = c$\n",
    "    - 인공 신경망을 그림으로 나타낼 때 활성화 함수를 생략하는 경우가 많음 (활성화 함수를 층에 포함되어 있다고 간주하기 떄문)\n",
    "- 많이 사용하는 활성화 함수 중 하나는 4장에서 배웠던 시그모이드 함수\n",
    "  - 뉴런의 출력 z 값을 0과 1 사이로 압축\n",
    "- keras로 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae790fbc-ca63-49ca-8b34-605a910a9555",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
    "dense2 = keras.layers.Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d611a6f5-8fd7-47b4-90fd-58423a80016f",
   "metadata": {},
   "source": [
    "- dense1은 은닉층이고 100개의 뉴런을 가진 밀집층. 은닉층 뉴런 개수를 정하는데에는 특별한 기준이 없음. 뉴런의 적절한 개수 판단은 상당한 경험이 필요함\n",
    "- 한가지 제약 사항은 출력층의 뉴런보다는 많게 만들어야 함 (클래스 10개 확률을 예측하는데 이전 은닉층의 뉴런 10개보다 적다면 정보가 부족할 것)\n",
    "- dense2는 출력층. 10개의 클래스를 분류하므로 10개의 뉴런을 두었고 활성화 함수는 소프트맥스로 지정\n",
    "\n",
    "### 심층 신경망 만들기\n",
    "- 앞서 만든 dense1, dense2를 Sequential 클래스에 추가하여 심층 신경망(DNN)을 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "694339d5-1fe6-47eb-b95e-6f2a6cb1afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층(dense2)을 리스트의 가장 마지막에 둘 것!\n",
    "model = keras.Sequential([dense1, dense2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed740d7f-d3cd-4247-a581-e2ad0ca40e1f",
   "metadata": {},
   "source": [
    "- 리스트는 가장 처음 등장하는 은닉층에서 자미작 출력층 순서로 나열해야 함\n",
    "- 인공 신경망의 강력한 성능은 층을 추가하며 입력 데이터에 대해 연속적인 학습을 진행하는 능력에서 나옴\n",
    "- 케라스는 모델의 summary() 메서드를 호출하면 층에 대한 유용한 정보를 얻을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9947c72b-e56c-46fd-93e9-575cdcd73680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f5c2e-bb55-4108-a6c4-3e2461462f93",
   "metadata": {},
   "source": [
    "- 첫 줄은 모델 이름\n",
    "- 이후 모델에 들어있는 층이 순서대로 나열\n",
    "- 순서는 리스트에 입력된 순서로 나열\n",
    "- 층마다 층 이름, 클래스, 출력 크기, 모델 파라미터 개수가 출력\n",
    "- 출력 크기(None, 100)\n",
    "  - 샘플 개수(None) -> 케라스 모델의 fit() 메서드에 훈련 데이터를 주입하면 데이터를 한 번에 모두 사용하지 않고 잘게 나누어 여러 번에 걸쳐 경사 하강법 단계를 수행 (미니배치 경사 하강법)\n",
    "  - 케라스 기본 미니배치 크기는 32개. 이 값은 fit() 메서드에 batch_size 매개변수로 바꿀 수 있음\n",
    "  - 샘플 개수를 고정하지 않고 어떤 배치 크기에도 유연하게 대응할 수 있도록 None으로 설정\n",
    "  - 신경망 층에 입력되거나 출력되는 배열의 첫 번째 차원을 배치 차원이라고 부름\n",
    "  - 두번째 출력은 : 뉴런 개수(100) -> 샘플마다 784개의 픽셀값이 은닉층을 통과하며 100개의 특성으로 압축\n",
    "  - 마지막으로 모델 파라미터 개수 출력(Param, 78500) : Dense 층이므로 입력 픽셀 784개와 100개의 모든 조합에 대한 가중치가 있음 + 뉴런마다 1개의 절편\n",
    "![Param-1](./dnn-373-1.jpg)\n",
    "- 두 번째 층의 출력 크기는 (None, 10) : 배치 차원은 동일하게 None이고 출력 뉴런 개수가 10개임\n",
    "- 이 층의 모델 파라미터 개수는 100개의 은닉층 뉴런과 10개의 출력층 뉴런이 모두 연결되고 출력층의 뉴런마다 하나의 절편이 있기 때문에 1,010개의 모델 파라미터가 있음\n",
    "![Param-2](./dnn-373-1.jpg)\n",
    "\n",
    "- summary() 메서드의 마지막에는 총 모델 파라미터 개수와 훈련 파라미터 개수가 동일하게 79,510개 -> 은닉층과 출력층의파라미터 개수를 합친 값\n",
    "- 훈련되지 않는 파라미터(Non-trainable params)는 0\n",
    "  - 간혹 경사 하강법으로 훈련되지 않는 파라미터를 가진 층이 있음\n",
    "  - 이런 층의 파라미터 개수가 여기 나타남\n",
    "\n",
    "### 층을 추가하는 다른 방법\n",
    "- 매개변수를 추가하여 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f072f37a-4249-4747-8cd2-88b36f2bd59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
    "                          keras.layers.Dense(10, activation='softmax', name='output')], name='패션 MNIST 모델')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f570ce30-0e7f-4350-b7ac-aaeed5f3e90b",
   "metadata": {},
   "source": [
    "- 해당 코드는 추가되는 층을 한눈에 알아보는 장점이 있음\n",
    "- 모델 이름과 층은 반드시 영문이어야 함\n",
    "- summary() 메서드 출력에서 확인 고고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6916e784-2820-46bf-badf-b91014e953ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"패션 MNIST 모델\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f911f18-9133-4e83-ae36-8d6c7b785595",
   "metadata": {},
   "source": [
    "- 이 방법이 편리하지만 많은 충을 추가하려면 코드가 너무 길어짐\n",
    "- 이럴땐 add() 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed08adf6-092b-4aa0-9a76-1886d14199d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10fe6f00-1d74-4795-aa87-1e536f9863f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 이 방법은 한눈에 층을 볼 수 있고 프로그램 실행 시 동적으로 층을 선택하여 추가 가능\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9a098c-6693-4c37-b112-42258d6badb2",
   "metadata": {},
   "source": [
    "- 이제 모델을 훈련해보자\n",
    "- compile() 메서드 설정은 1절에서 했던 것과 동일\n",
    "- 5번의 에포크 동안 훈련해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64bfc4f2-113f-4c65-9c79-b533f753139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5704 - accuracy: 0.8051\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4129 - accuracy: 0.8524\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3766 - accuracy: 0.8627\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3546 - accuracy: 0.8704\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3360 - accuracy: 0.8783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x13297c990>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22445ed-626f-463c-9d22-65cd91e64864",
   "metadata": {},
   "source": [
    "- 훈련 세트에 대한 성능을 보면 추가된 층이 성능을 향상시켰다는 것을 알 수 있음\n",
    "- 인공 신경망에 몇 개의 층을 추가하더라도 compile()메서드와 fit() 메서드의 사용은 동일 (keras API 장점)\n",
    "- 이미지 분류에서 높은 성능을 낼 수 있는 활성화 함수에 대해 알아보자\n",
    "\n",
    "### 렐루 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f9bd4-729b-4a09-83ba-e3222220edea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
